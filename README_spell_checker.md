# 基于 IDF + Jaccard 相似度的拼写错误检测脚本

## 概述

这是一个基于纯数学方法的拼写错误检测脚本，**不需要模型训练**。它利用了两个核心概念：

1. **IDF (逆文档频率)**: 识别罕见词（可能是拼写错误）
2. **Jaccard 相似度**: 找到与罕见词相似的高频词（可能是正确的词）

## 核心逻辑

### 第一步：IDF 识别罕见词

如果一个词在文档中出现频率极低（IDF 值很高），它可能是：
- 生僻的专业术语
- **拼写错误**

### 第二步：Jaccard 相似度匹配

对于每个罕见词，使用 Jaccard 相似度（基于 bigram）在高频词表中寻找相似词：
- 如果找到高度相似的高频词 → 判定为拼写错误
- 如果找不到相似词 → 可能是真正的生僻词

### 数学公式

**IDF 公式：**
```
IDF(word) = log(总文档数 / 包含该词的文档数)
```

**Jaccard 相似度（基于 bigram）：**
```
J(A, B) = |A ∩ B| / |A ∪ B|
```

其中 A 和 B 是两个词的 bigram 集合。

## 使用方法

```bash
python3 spell_checker_idf_jaccard.py
```

### 输入文件

- `spelling_analysis_combined_batch_ulhdemmplr.json`: 包含评论文本的 JSON 文件

### 输出文件

- `spelling_errors_detected_idf_jaccard.json`: 检测到的拼写错误列表

## 参数调整

在 `main()` 函数中可以调整以下参数：

```python
detected_errors = detect_spelling_errors(
    reviews,
    min_word_freq=2,              # 词频阈值（低于此值认为是罕见词）
    min_idf_threshold=5.0,       # IDF 阈值（高于此值认为是罕见词）
    min_similarity=0.5,           # Jaccard 相似度阈值
    top_frequent_words=10000      # 用于比较的高频词数量
)
```

### 参数说明

- **min_word_freq**: 词频低于此值的词被认为是罕见词
- **min_idf_threshold**: IDF 值高于此值的词被认为是罕见词
  - 对于小数据集（< 1000 文档），建议设置为 4.0-5.0
  - 对于大数据集，可以设置为 8.0-10.0
- **min_similarity**: Jaccard 相似度阈值
  - 0.5-0.6: 较宽松，可能捕获更多错误但误报也更多
  - 0.6-0.7: 较严格，误报更少但可能漏掉一些错误
- **top_frequent_words**: 用于相似度比较的高频词数量

## 输出格式

```json
[
  {
    "original_word": "bublegum",
    "corrected_word": "bubblegum",
    "similarity": 0.857,
    "edit_distance": 1,
    "idf": 5.63,
    "frequency": 1,
    "all_candidates": [
      {
        "word": "bubblegum",
        "similarity": 0.857,
        "edit_distance": 1
      }
    ]
  }
]
```

## 方法局限性

### 1. 需要正确的词在数据集中存在

**核心问题**: 如果正确的词（如 "bubblegum"）在数据集中不存在或频率很低，算法无法找到它。

**示例**:
- 错误词: "bublegum" (IDF=5.63, 频率=1)
- 正确词: "bubblegum" (在数据集中不存在)
- 结果: 无法检测到错误，因为找不到相似的高频词

**解决方案**:
- 使用外部词典（如英语词典）作为高频词表
- 结合预训练的词向量模型

### 2. 小数据集的挑战

在小数据集（< 1000 文档）中：
- 很多正常词只出现 1-2 次，被误判为罕见词
- 需要降低 IDF 阈值，但会增加误报

**建议**:
- 对于小数据集，使用外部词典
- 或者结合其他特征（如编辑距离、语言模型概率）

### 3. 误报问题

一些正常词可能被误判为错误：
- "pressed" → "impressed" (误报)
- "morning" → "turning" (误报)

**改进方向**:
- 结合语言模型概率
- 使用更复杂的相似度度量
- 添加上下文信息

## 适用场景

✅ **适合**:
- 大规模文本数据（> 10,000 文档）
- 需要快速、无需训练的解决方案
- 需要可解释的结果

❌ **不适合**:
- 小数据集（< 1000 文档）
- 需要高精度的场景
- 正确的词不在数据集中的情况

## 性能优化建议

1. **使用外部词典**: 将英语词典作为高频词表，而不是依赖数据集中的词频
2. **并行处理**: 对于大规模数据，可以并行计算相似度
3. **缓存机制**: 缓存已计算的相似度值
4. **早期终止**: 如果找到相似度 > 0.9 的词，可以提前终止搜索

## 扩展方向

1. **结合编辑距离**: 已经实现，可以进一步优化权重
2. **使用 N-gram 语言模型**: 评估候选词的语言模型概率
3. **上下文感知**: 考虑单词在句子中的上下文
4. **多语言支持**: 扩展到其他语言

## 参考文献

- BM25 算法（BM25 是 IDF 的扩展）
- Jaccard 相似度（集合论基础）
- 拼写纠错经典方法（Peter Norvig 的拼写纠错器）
