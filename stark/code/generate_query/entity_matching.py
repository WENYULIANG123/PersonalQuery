#!/usr/bin/env python3
"""
å®ä½“åŒ¹é…æ¨¡å—
è´Ÿè´£åŒ¹é…äº§å“å®ä½“å’Œç”¨æˆ·åå¥½å®ä½“
"""

import os
import json
import sys
from typing import Dict, List
from datetime import datetime

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from model import call_llm_with_retry, APIErrorException, ApiProvider
from utils import get_all_api_keys_in_order, create_llm_with_config, try_api_keys_with_fallback

def log_with_timestamp(message: str):
    """Log message with timestamp."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}", flush=True)

def create_llm_with_config(api_config):
    """Create LLM with config based on provider."""
    from langchain_openai import ChatOpenAI

    provider = api_config.get('provider', 'siliconflow')

    if provider == 'siliconflow':
        return ChatOpenAI(
            base_url="https://api.siliconflow.cn/v1",
            api_key=api_config['api_key'],
            model_name=api_config.get('model', 'Qwen/Qwen2.5-7B-Instruct'),
            temperature=0.1,
            max_tokens=4000,
            timeout=60
        )
    else:
        # Default to OpenAI
        return ChatOpenAI(
            api_key=api_config['api_key'],
            model_name=api_config.get('model', 'gpt-3.5-turbo'),
            temperature=0.1,
            max_tokens=4000,
            timeout=60
        )

def try_api_keys_with_fallback(api_keys: List[Dict], operation_func, context: str, success_message: str = None, error_message: str = None):
    """
    é€šç”¨API keyå¾ªç¯é‡è¯•å‡½æ•°

    Args:
        api_keys: API keyé…ç½®åˆ—è¡¨
        operation_func: è¦æ‰§è¡Œçš„æ“ä½œå‡½æ•°ï¼Œå‚æ•°ä¸º(api_config, provider_name, key_index)
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨äºæ—¥å¿—
        success_message: æˆåŠŸæ—¶çš„æ—¥å¿—æ¶ˆæ¯æ¨¡æ¿
        error_message: é”™è¯¯æ—¶çš„æ—¥å¿—æ¶ˆæ¯æ¨¡æ¿

    Returns:
        (result, success) å…ƒç»„ï¼Œresultæ˜¯æ“ä½œç»“æœï¼Œsuccessè¡¨ç¤ºæ˜¯å¦æˆåŠŸ
    """
    for key_index, api_config in enumerate(api_keys):
        provider_name = "SiliconFlow" if api_config['provider'] == ApiProvider.SILICONFLOW else "Unknown"
        try:
            result = operation_func(api_config, provider_name, key_index)

            # æˆåŠŸå¤„ç†
            # if success_message:
            #     log_with_timestamp(success_message.format(
            #         context=context,
            #         provider=provider_name,
            #         key_num=api_config['key_index'] + 1,
            #     ))
            return result, True
        except APIErrorException as e:
            # APIé”™è¯¯ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªkey
            if error_message:
                log_with_timestamp(error_message.format(
                    context=context,
                    provider=provider_name,
                    key_num=api_config['key_index'] + 1,
                    error=str(e)
                ))
            continue
        except Exception as e:
            # å…¶ä»–é”™è¯¯ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªkey
            log_with_timestamp(f"âŒ Unexpected error with {provider_name} Key #{api_config['key_index'] + 1}: {e}")
            continue

    # æ‰€æœ‰keyéƒ½å¤±è´¥äº†
    return None, False


def process_entity_matching_response(response_str: str) -> List[str]:
    """
    å¤„ç†å®ä½“åŒ¹é…çš„LLMå“åº”

    Args:
        response_str: LLMè¿”å›çš„åŸå§‹å­—ç¬¦ä¸²

    Returns:
        å¤„ç†åçš„å®ä½“åˆ—è¡¨

    Raises:
        APIErrorException: å½“å“åº”æ— æ•ˆæˆ–æ— æ³•è§£ææ—¶
    """
    # Debug: print raw response
    print(f"ğŸ” Entity matching raw response (first 500 chars): {response_str[:500]!r}", flush=True)

    # Check for markdown code blocks
    if response_str.startswith('```') and '```' in response_str:
        print("ğŸ“¦ Found markdown code block, extracting JSON...", flush=True)

    if not response_str:
        raise APIErrorException("No response from entity matching")

    try:
        # Clean the response
        response_str = response_str.strip()

        # Smart JSON extraction for Chain of Thought responses
        lines = response_str.strip().split('\n')
        json_found = False

        # Check if the last few lines contain valid JSON
        for i in range(len(lines) - 1, max(-1, len(lines) - 5), -1):  # Check last 5 lines
            line = lines[i].strip()
            if line.startswith('[') and line.endswith(']'):
                # Found JSON array at the end
                response_str = line
                json_found = True
                break
            elif line.startswith('{') and line.endswith('}'):
                # Found JSON object at the end
                response_str = line
                json_found = True
                break

        # If no JSON found at the end, look for code blocks
        if not json_found:
            # Find the LAST json code block (in case there are multiple)
            json_blocks = []
            start = 0
            while True:
                json_start = response_str.find('```json', start)
                if json_start == -1:
                    break
                json_end = response_str.find('```', json_start + 7)
                if json_end == -1:
                    break
                content_start = response_str.find('\n', json_start) + 1
                if content_start > 0:
                    content = response_str[content_start:json_end].strip()
                    if content:
                        json_blocks.append(content)
                start = json_end + 3

            # Also handle regular ``` blocks
            if not json_blocks:
                if '```' in response_str:
                    # Find the LAST code block
                    last_triple = response_str.rfind('```')
                    first_triple = response_str.rfind('```', 0, last_triple)
                    if first_triple != last_triple:
                        content_start = response_str.find('\n', first_triple) + 1
                        if content_start > 0:
                            response_str = response_str[content_start:last_triple].strip()
                    else:
                        # Single code block
                        content_start = response_str.find('\n', first_triple) + 1
                        if content_start > 0:
                            response_str = response_str[content_start:].strip()
                elif json_blocks:
                    response_str = json_blocks[-1]  # Use the last json block

        # Try to parse as JSON
        print(f"ğŸ”„ Attempting to parse JSON: {response_str[:200]!r}", flush=True)
        result = json.loads(response_str)
        print(f"âœ… JSON parsed successfully: {result}", flush=True)

        # Handle different response formats
        if isinstance(result, list):
            # Array format - expected for entity matching
            flattened = []
            for item in result:
                if isinstance(item, str):
                    flattened.append(item)
                elif isinstance(item, list):
                    # Flatten nested list but only take string elements
                    for subitem in item:
                        if isinstance(subitem, str):
                            flattened.append(subitem)

            if flattened:
                return flattened
            else:
                raise APIErrorException("No valid entities extracted from entity matching (empty result)")

        elif isinstance(result, dict):
            # If somehow returns dict, try to extract matched entities
            flattened = []
            possible_keys = ["matched_entities", "matches", "results"]
            for key in possible_keys:
                if key in result and isinstance(result[key], list):
                    for item in result[key]:
                        if isinstance(item, str) and item.strip():
                            flattened.append(item.strip())

            if flattened:
                return flattened
            else:
                raise APIErrorException("No valid entities extracted from entity matching (empty result)")

        else:
            raise APIErrorException("Invalid result format from entity matching")

    except json.JSONDecodeError as e:
        print(f"JSON parsing error in entity matching: {e}", flush=True)
        raise APIErrorException("JSON parsing failed in entity matching")
    except Exception as e:
        print(f"Unexpected error processing entity matching response: {e}", flush=True)
        raise APIErrorException("Response processing failed in entity matching")

def match_product_and_user_entities_no_llm(product_entities: Dict[str, List[str]], user_entities: Dict[str, List[str]], llm_model) -> Dict[str, List[str]]:
    """
    ä½¿ç”¨LLMè¿›è¡Œå®ä½“åŒ¹é…ï¼šå¯¹æ¯ä¸ªç”¨æˆ·åå¥½å®ä½“ï¼Œåœ¨ç›¸åŒç±»åˆ«çš„äº§å“å®ä½“ä¸­æ‰¾åˆ°ç›¸ä¼¼åº¦æœ€å¤§çš„å®ä½“

    Args:
        product_entities: å•†å“å®ä½“å­—å…¸ {category: [entities]}
        user_entities: ç”¨æˆ·åå¥½å®ä½“å­—å…¸ {category: [entities]}
        llm_model: LLMæ¨¡å‹ç”¨äºè®¡ç®—ç›¸ä¼¼åº¦

    Returns:
        åŒ¹é…çš„å®ä½“å­—å…¸ {category: [matched_entities]}
    """
    matched_entities = {}

    # éå†ç”¨æˆ·åå¥½å®ä½“çš„æ‰€æœ‰ç±»åˆ«
    for user_category, user_entity_list in user_entities.items():
        # å¦‚æœäº§å“å®ä½“ä¸­ä¹Ÿå­˜åœ¨è¿™ä¸ªç±»åˆ«
        if user_category in product_entities:
            product_entity_list = product_entities[user_category]
            matched_in_category = []

            # å¯¹æ¯ä¸ªç”¨æˆ·åå¥½å®ä½“ï¼Œåœ¨äº§å“å®ä½“ä¸­æ‰¾åˆ°æœ€ç›¸ä¼¼çš„
            matched_product_entities = set()  # ç”¨äºå»é‡åŒ¹é…çš„äº§å“å®ä½“
            for user_entity in user_entity_list:
                best_match = find_most_similar_entity_with_llm(user_entity, product_entity_list, llm_model)
                if best_match and best_match not in matched_product_entities:
                    matched_in_category.append(best_match)
                    matched_product_entities.add(best_match)

            if matched_in_category:
                matched_entities[user_category] = matched_in_category

    return matched_entities

def find_most_similar_entity_with_llm(user_entity: str, product_entities: List[str], llm_model) -> str:
    """
    ä½¿ç”¨LLMåœ¨äº§å“å®ä½“åˆ—è¡¨ä¸­æ‰¾åˆ°ä¸ç”¨æˆ·å®ä½“æœ€ç›¸ä¼¼çš„å®ä½“

    Args:
        user_entity: ç”¨æˆ·åå¥½å®ä½“
        product_entities: äº§å“å®ä½“åˆ—è¡¨
        llm_model: LLMæ¨¡å‹

    Returns:
        æœ€ç›¸ä¼¼çš„äº§å“å®ä½“ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not product_entities:
        return ""

    # å¦‚æœåªæœ‰ä¸€ä¸ªäº§å“å®ä½“ï¼Œç›´æ¥è¿”å›
    if len(product_entities) == 1:
        return product_entities[0]

    prompt = f"""
You are an expert at finding semantic similarity between product features.

Given:
- User preference entity: "{user_entity}"
- Product entities to compare: {product_entities}

Find the product entity that is most semantically similar to the user preference entity.
Consider synonyms, related concepts, and contextual similarity.

**OUTPUT REQUIREMENT:**
Return ONLY the most similar product entity as a JSON string. No explanations.

Example:
- User: "24 colors" â†’ Product entities: ["24", "12", "36"] â†’ Output: "24"
- User: "waterproof" â†’ Product entities: ["water resistant", "durable", "lightweight"] â†’ Output: "water resistant"

Output format:
"most_similar_entity"
"""

    # Retry up to 3 times
    for attempt in range(3):
        try:
            response_str, success = call_llm_with_retry(llm_model, prompt, context="entity_similarity")
            if success and response_str:
                # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                try:
                    # ç§»é™¤å¯èƒ½çš„å¼•å·åŒ…è£…
                    if response_str.startswith('"') and response_str.endswith('"'):
                        result = response_str[1:-1]
                    else:
                        result = response_str.strip()

                    # æ£€æŸ¥ç»“æœæ˜¯å¦åœ¨äº§å“å®ä½“åˆ—è¡¨ä¸­
                    if result in product_entities:
                        return result
                    else:
                        # å¦‚æœä¸åœ¨åˆ—è¡¨ä¸­ï¼Œå°è¯•æ‰¾åˆ°æœ€ç›¸ä¼¼çš„
                        for product_entity in product_entities:
                            if result.lower() in product_entity.lower() or product_entity.lower() in result.lower():
                                return product_entity

                except Exception as e:
                    print(f"Error parsing LLM response for similarity: {e}", flush=True)

        except Exception as e:
            print(f"LLM error in entity similarity: {e}", flush=True)
            if attempt < 2:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                continue

    # å¦‚æœLLMå¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    return ""

def match_product_and_user_entities(product_entities: List[str], user_entities: List[str], llm_model) -> List[str]:
    """ä½¿ç”¨LLMåŒ¹é…äº§å“å®ä½“å’Œç”¨æˆ·åå¥½å®ä½“ï¼Œæ‰¾å‡ºåŒ¹é…çš„å®ä½“"""
    if not product_entities or not user_entities:
        return []

    # ç®€åŒ–çš„å®ä½“åŒ¹é…promptï¼Œç›´æ¥è¦æ±‚JSONè¾“å‡º
    prompt = f"""
You are an expert at matching product features with user preferences.

Given:
- Product Entities: {product_entities}
- User Preferences: {user_entities}

Find entities that appear in both lists OR are semantically equivalent (synonyms or closely related).

**OUTPUT REQUIREMENT:**
Return ONLY a JSON array of matched entities. No explanations.

Examples:
- If "color" appears in both lists â†’ ["color"]
- If "size" in products and "dimensions" in user preferences â†’ ["size"]
- If no matches â†’ []

```json

```json
[]
```

Begin your analysis now.
"""

    # Retry up to 5 times for JSON parsing errors in matching
    json_parse_retries = 5
    for attempt in range(json_parse_retries):
        try:
            response_str, success = call_llm_with_retry(llm_model, prompt, context="entity_matching")
            if success and response_str:
                entities = process_entity_matching_response(response_str)

                # Filter to ensure only strings and remove duplicates (specific to matching)
                matched_entities = []
                for item in entities:
                    if isinstance(item, str) and item.strip():
                        clean_item = item.strip()
                        if clean_item not in matched_entities:
                            matched_entities.append(clean_item)

                return matched_entities
        except APIErrorException as e:
            # Check if this is a JSON parsing error
            error_msg = str(e)
            if "JSON parsing failed" in error_msg or "JSON parsing error" in error_msg:
                if attempt < json_parse_retries - 1:
                    print(f"JSON parsing failed in matching (attempt {attempt + 1}/{json_parse_retries}), retrying...", flush=True)
                    continue
                else:
                    print(f"JSON parsing failed in matching after {json_parse_retries} attempts", flush=True)
            # For matching, we return empty list on error instead of raising
            return []
        except Exception as e:
            print(f"LLM error in entity matching: {e}", flush=True)
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©API keyå¾ªç¯å¤„ç†

    return []


def perform_entity_matching(products: List[Dict], max_workers: int = 20) -> List[Dict]:
    """æ‰§è¡Œäº§å“å®ä½“å’Œç”¨æˆ·åå¥½å®ä½“çš„åŒ¹é…"""
    log_with_timestamp(f"ğŸ”— Starting entity matching for {len(products)} products...")

    if not products:
        log_with_timestamp("âš ï¸ No products found for matching")
        return products

    # è·å–API keysç”¨äºLLMåŒ¹é…
    all_api_keys = get_all_api_keys_in_order()

    matched_count = 0
    total_products = len(products)

    for idx, product in enumerate(products):
        try:
            asin = product.get('asin', 'Unknown')
            product_entities = product.get('product_entities', {})
            user_entities = product.get('user_preference_entities', {})

            # ä½¿ç”¨LLMè¿›è¡Œå®ä½“ç›¸ä¼¼åº¦åŒ¹é…
            def matching_operation(api_config, provider_name, key_index):
                llm_model = create_llm_with_config(api_config)
                return match_product_and_user_entities_no_llm(product_entities, user_entities, llm_model)

            matched_entities, success = try_api_keys_with_fallback(
                all_api_keys,
                matching_operation,
                f"{asin} entity matching"
            )

            if not success:
                matched_entities = {}

            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„å®ä½“
            has_matches = any(matches for matches in matched_entities.values())

            # æ·»åŠ åŒ¹é…ç»“æœåˆ°äº§å“æ•°æ®
            product['matched_entities'] = matched_entities

            # ç”Ÿæˆæ ¼å¼åŒ–çš„è¾“å‡ºå­—ç¬¦ä¸²
            formatted_output = generate_formatted_product_output(product, idx, total_products)
            product['formatted_output'] = formatted_output

            if has_matches:
                matched_count += 1

            # æ¯å¤„ç†10ä¸ªäº§å“æˆ–æœ€åä¸€æ‰¹æ—¶è¾“å‡ºè¿›åº¦
            if (idx + 1) % 10 == 0 or idx + 1 == total_products:
                log_with_timestamp(f'ğŸ“Š Entity matching progress: {idx + 1}/{total_products} products processed')

        except Exception as e:
            log_with_timestamp(f'âŒ Exception in entity matching for {asin}: {e}')
            product['matched_entities'] = {}
            product['formatted_output'] = generate_formatted_product_output(product, idx, total_products)

    log_with_timestamp(f'âœ… Entity matching completed! {matched_count}/{total_products} products have matched entities')
    return products



def generate_formatted_product_output(product, idx, total_products):
    """ç”Ÿæˆæ ¼å¼åŒ–çš„äº§å“è¾“å‡ºå­—ç¬¦ä¸²"""
    asin = product.get('asin', 'Unknown')
    product_title = product.get('product_title', 'Unknown Product')
    product_entities = product.get('product_entities', [])
    user_entities = product.get('user_preference_entities', [])
    matched_entities = product.get('matched_entities', [])

    output_lines = [
        f"[{idx+1}/{total_products}] Product: {product_title}",
        f"ASIN: {asin}",
        f"Product Entities ({len(product_entities)}): {', '.join(product_entities) if product_entities else 'None'}",
        f"User Preference Entities ({len(user_entities)}): {', '.join(user_entities) if user_entities else 'None'}",
        f"Matched Entities ({len(matched_entities)}): {', '.join(matched_entities) if matched_entities else 'None'}",
        ""
    ]

    return "\n".join(output_lines)