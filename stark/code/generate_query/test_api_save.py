#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯APIåŸå§‹å“åº”ä¿å­˜åŠŸèƒ½
"""

import os
import sys
import json

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from model import get_gm_model, call_llm_with_retry, set_api_responses_file

def test_api_response_saving():
    """æµ‹è¯•APIå“åº”ä¿å­˜åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•APIåŸå§‹å“åº”ä¿å­˜åŠŸèƒ½")
    print("=" * 60)
    
    # è®¾ç½®ä¿å­˜è·¯å¾„
    workspace_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    result_dir = os.path.join(workspace_root, "result")
    os.makedirs(result_dir, exist_ok=True)
    
    api_responses_file = os.path.join(result_dir, "api_raw_responses_test.json")
    set_api_responses_file(api_responses_file)
    print(f"ğŸ“ APIå“åº”å°†ä¿å­˜åˆ°: {api_responses_file}")
    print()
    
    # åˆå§‹åŒ–æ¨¡å‹
    print("ğŸ¤– åˆå§‹åŒ–LLMæ¨¡å‹...")
    try:
        llm_model = get_gm_model()
        print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    print()
    
    # æµ‹è¯•1: ç®€å•æŸ¥è¯¢
    print("ğŸ“ æµ‹è¯•1: ç®€å•æŸ¥è¯¢")
    print("-" * 60)
    test_prompt_1 = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»Pythonç¼–ç¨‹è¯­è¨€ã€‚"
    print(f"Prompt: {test_prompt_1}")
    
    try:
        response, success = call_llm_with_retry(
            llm_model, 
            test_prompt_1, 
            max_retries=1, 
            context="test_simple_query",
            use_openai_client=True
        )
        if success:
            print("âœ… è°ƒç”¨æˆåŠŸ")
            print(f"å“åº”å†…å®¹: {response}")
            print(f"å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        else:
            print("âŒ è°ƒç”¨å¤±è´¥")
    except Exception as e:
        print(f"âŒ è°ƒç”¨å¼‚å¸¸: {e}")
    
    print()
    
    # æµ‹è¯•2: JSONæ ¼å¼æŸ¥è¯¢
    print("ğŸ“ æµ‹è¯•2: JSONæ ¼å¼æŸ¥è¯¢")
    print("-" * 60)
    test_prompt_2 = """è¯·è¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
{
  "name": "æµ‹è¯•äº§å“",
  "price": 100,
  "category": "ç”µå­äº§å“"
}"""
    print(f"Prompt: {test_prompt_2[:50]}...")
    
    try:
        response, success = call_llm_with_retry(
            llm_model, 
            test_prompt_2, 
            max_retries=1, 
            context="test_json_query",
            use_openai_client=True
        )
        if success:
            print("âœ… è°ƒç”¨æˆåŠŸ")
            print(f"å“åº”å†…å®¹: {response}")
            print(f"å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        else:
            print("âŒ è°ƒç”¨å¤±è´¥")
    except Exception as e:
        print(f"âŒ è°ƒç”¨å¼‚å¸¸: {e}")
    
    print()
    
    # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
    print("ğŸ“‹ éªŒè¯ä¿å­˜çš„æ–‡ä»¶")
    print("-" * 60)
    
    if os.path.exists(api_responses_file):
        print(f"âœ… æ–‡ä»¶å­˜åœ¨: {api_responses_file}")
        
        try:
            with open(api_responses_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            
            print(f"ğŸ“Š ä¿å­˜äº† {len(saved_data)} æ¡APIè°ƒç”¨è®°å½•")
            print()
            
            for idx, record in enumerate(saved_data, 1):
                print(f"è®°å½• {idx}:")
                print(f"  æ—¶é—´æˆ³: {record.get('timestamp', 'N/A')}")
                print(f"  åœºæ™¯: {record.get('context', 'N/A')}")
                print(f"  APIä¿¡æ¯: {record.get('api_info', 'N/A')}")
                print(f"  æˆåŠŸ: {record.get('success', False)}")
                print(f"  Prompté•¿åº¦: {record.get('prompt_length', 0)}")
                print(f"  å“åº”é•¿åº¦: {record.get('response_length', 0)}")
                print(f"  æ¨ç†é•¿åº¦: {record.get('reasoning_length', 0)}")
                
                # æ˜¾ç¤ºè¯¦ç»†çš„å“åº”å†…å®¹
                raw_response = record.get('raw_response', {})
                if isinstance(raw_response, dict):
                    reasoning_content = raw_response.get('reasoning_content', '')
                    content = raw_response.get('content', '')
                    
                    if reasoning_content:
                        print(f"  æ¨ç†å†…å®¹: {reasoning_content[:200]}{'...' if len(reasoning_content) > 200 else ''}")
                    else:
                        print(f"  æ¨ç†å†…å®¹: (ç©º)")
                    
                    if content:
                        print(f"  å›å¤å†…å®¹: {content[:200]}{'...' if len(content) > 200 else ''}")
                    else:
                        print(f"  å›å¤å†…å®¹: (ç©º)")
                else:
                    # å…¼å®¹æ—§æ ¼å¼
                    print(f"  åŸå§‹å“åº”: {str(raw_response)[:200]}...")
                
                if record.get('error'):
                    print(f"  é”™è¯¯: {record.get('error', 'N/A')}")
                print()
            
            print("âœ… æ‰€æœ‰APIè°ƒç”¨è®°å½•å·²æˆåŠŸä¿å­˜ï¼")
            return True
            
        except Exception as e:
            print(f"âŒ è¯»å–ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return False
    else:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {api_responses_file}")
        return False

if __name__ == "__main__":
    success = test_api_response_saving()
    print()
    print("=" * 60)
    if success:
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    else:
        print("âš ï¸ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜")
    print("=" * 60)
    sys.exit(0 if success else 1)
